# -*- coding: utf-8 -*-
"""ProyectoFinal_Predicción_Cáncer_de_Pulmón.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F0Q0eMLA2SP87TzwH0btFSEI07c4TJ_K

# Conexion con google drive y seleccion del directorio de trabajo
"""

from google.colab import drive # conectarse con google drive
from importlib.machinery import SourceFileLoader # Caragar nodulos desde un directorio

drive.mount('/content/drive') # conectarnos con el google drive

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/Cibertec/ProyectoFinal_Binomial

"""/content/drive/MyDrive/Cibertec/Sistemas de aprendizaje automatico"""

!ls

!unzip chest_cancer_images.zip -d chest_cancer_images

!ls /content/drive/MyDrive/Cibertec/ProyectoFinal_Binomial/chest_cancer_images/test

!ls /content/drive/MyDrive/Cibertec/ProyectoFinal_Binomial/chest_cancer_images/train

"""# Exploracion de la data de entrenamiento"""

# Explorar una imagen de ejemplo
from PIL import Image
import matplotlib.pyplot as plt

# Leer el archivo PNG
ruta_imagen = '/content/drive/MyDrive/Cibertec/ProyectoFinal_Binomial/chest_cancer_images/train/1/000000 (6).png'
imagen = Image.open(ruta_imagen)

# Mostrar la imagen
plt.imshow(imagen)
plt.axis('off')  # Opcional: Oculta los ejes
plt.title("Imagen PNG")
plt.show()

# Convertir a array numpy
import numpy as np
imagen_array = np.array(imagen)
imagen_array.shape

"""RGB + Alpha (transparencia) = 4

# Cargando el dataset con tensowflow
"""

import tensorflow as tf

# Ruta a los datos
train_dir = "/content/drive/MyDrive/Cibertec/ProyectoFinal_Binomial/chest_cancer_images/train"
val_dir = "/content/drive/MyDrive/Cibertec/ProyectoFinal_Binomial/chest_cancer_images/test"

# # Parámetros optimizados
img_height = 128  # Tamaño estándar para transfer learning
img_width = 128   # Ancho de las imágenes
batch_size = 32  # Tamaño más manejable para imágenes grandes
seed = 42         # Para reproducibilidad

"""CARGA Y PREPROCESAMIENTO DE DATOS"""

# Cargar datasets con validación cruzada
train_ds = tf.keras.utils.image_dataset_from_directory(
    train_dir,
    image_size=(img_height, img_width),
    batch_size=batch_size,
    label_mode='int',
    color_mode='grayscale',
    shuffle=True
)

val_ds = tf.keras.utils.image_dataset_from_directory(
    val_dir,
    image_size=(img_height, img_width),
    batch_size=batch_size,
    label_mode='int',
    color_mode='grayscale',
    shuffle=False
)

train_ds

val_ds

# Visualizar algunas imágenes del dataset

class_names = ['0', '1']

plt.figure(figsize=(12, 8))
for images, labels in train_ds.take(1):
    for i in range(min(9, len(images))):
        plt.subplot(3, 3, i + 1)
        img = images[i].numpy().astype("uint8")

        # Mostrar imagen en escala de grises si es necesario
        if img.shape[-1] == 1:
            img = img.squeeze()  # elimina la dimensión de canal
            plt.imshow(img, cmap="gray")
        else:
            plt.imshow(img)

        # Convertir etiqueta one-hot a índice de clase
        class_index = labels[i].numpy()
        plt.title(f"Clase: {class_names[class_index]}")
        plt.axis("off")

plt.tight_layout()
plt.show()

"""Vamos a ver una imagen dentro del dataset leido por tensorflow"""

# Convertir el dataset a un iterador
first_batch = next(iter(train_ds))  # Obtener el primer lote
first_image = first_batch[0][0].numpy().squeeze()  # Primera imagen del lote
first_label = first_batch[1][0].numpy()  # Primera etiqueta del lote
print("Etiqueta de la imagen:", first_label)
print("Matriz de la imagen:")

"""# Transformacion de los datos

Ese código se utiliza en TensorFlow para optimizar el rendimiento durante el entrenamiento y evaluación de modelos, especialmente al trabajar con datos grandes o cargados en tiempo real. Veamos en detalle lo que hace cada parte:

OPTIMIZACIÓN DE RENDIMIENTO
"""

AUTOTUNE = tf.data.AUTOTUNE

# Configurar para mejor rendimiento
train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)

# Normalización
normalization_layer = tf.keras.layers.Rescaling(1./255)

#train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))
#val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))
train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y)).cache().shuffle(1000).prefetch(AUTOTUNE)
val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y)).cache().prefetch(AUTOTUNE)

for images, labels in train_ds.take(1):
    print("Min pixel value:", tf.reduce_min(images).numpy())
    print("Max pixel value:", tf.reduce_max(images).numpy())

"""# Entrenamineto del modelo"""

model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3),  #1 convolución
                           activation='relu',
                           input_shape=(img_height, img_width,1)), #cambiar el 3 por 1 en caso de imagenes que no sean RGB.
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(2, activation='softmax')  # Ajusta para tu número de clases
])

model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Entrenamiento
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=10
)

import tensorflow as tf
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.regularizers import l2

# Modelo CNN con Dropout y Regularización L2
model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3),
                           activation='relu',
                           kernel_regularizer=l2(0.001),
                           input_shape=(img_height, img_width, 1)),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=l2(0.001)),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(2, activation='softmax')  # Ajusta a tu número de clases
])

# Compilar el modelo con categorical_crossentropy
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Callbacks
early_stop = EarlyStopping(
    monitor='val_loss',
    patience=3,
    restore_best_weights=True,
    verbose=1
)

checkpoint = ModelCheckpoint(
    "mejor_modelo.keras",
    monitor='val_loss',
    save_best_only=True,
    verbose=1
)

# Entrenamiento
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=30,
    callbacks=[early_stop, checkpoint]
)

print(history.history)

"""# Evaluacion del modelo"""

import matplotlib.pyplot as plt

# Extraer valores de pérdida (loss) y pérdida de validación (val_loss)
loss = history.history['loss']
val_loss = history.history['val_loss']

# Graficar
epochs = range(1, len(loss) + 1)

plt.figure(figsize=(8, 6))
plt.plot(epochs, loss, 'b', label='Pérdida de Entrenamiento')
plt.plot(epochs, val_loss, 'r', label='Pérdida de Validación')
plt.title('Pérdida por Epoch')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.grid()
plt.show()

print("Loss:", history.history['loss'])
print("Val Loss:", history.history['val_loss'])

"""Este gráfico muestra la evolución de la pérdida (loss) del modelo durante el entrenamiento y la validación a lo largo de las épocas. Aquí está mi interpretación:

**Evolución de la pérdida y precisión**
Loss de entrenamiento: Disminuye constantemente desde ~23.9 (época 1) hasta ~0.96 (época 27). Esto indica que el modelo está aprendiendo muy bien sobre los datos de entrenamiento.

Loss de validación: También baja desde ~3.19 hasta ~0.58 en la época 24, lo cual es positivo: tu modelo mejora también en datos no vistos.

Precisión (accuracy): Mejora desde ~11% en la época 1, llega a ~98% en validación alrededor de la época 24.

En la época 24 la pérdida de validación alcanza 0.5843, la más baja registrada.
Por eso model.save() se activó de nuevo y se guardaron esos pesos como “mejor_modelo.h5”

**Overfitting:**
A partir de la época 25 la pérdida de entrenamiento sigue bajando (hasta ~0.95 en la época 26-27).
Sin embargo, la pérdida de validación se estanca o sube (se sitúa alrededor de 0.59-0.63).

El accuracy también comienza a bajar o estabilizarse. Esto significa que el modelo está ajustándose demasiado a los datos de entrenamiento y empieza a generalizar peor en los datos de validación, clásico síntoma de overfitting.

**Early stopping**
Se configuró el early stopping y se activó tras la época 27 al no ver mejora tras varias épocas. El modelo restauró los pesos de la época 24, donde la validación fue óptima. Esa es la correcta estrategia para evitar un entrenamiento excesivo.
"""

# Evaluar en el conjunto de validación
#val_loss, val_accuracy = model.evaluate(val_ds)
#print(f"Pérdida en validación: {val_loss}")
#print(f"Precisión en validación: {val_accuracy}")

# === Evaluación ===
val_loss, val_accuracy = model.evaluate(val_ds)
print(f"Validación - Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}")

"""# Despliegue del modelo I"""

# Guardar el modelo entrenado
#model.save("model_frutas_verduras.h5")  #el modelo ya está guardado como "mejor_modelo.h5" en la etapa de entrenamiento

# Cargar el modelo
loaded_model = tf.keras.models.load_model("mejor_modelo.keras")

# Obtener predicciones
#y_pred = model.predict(val_ds)

# Convertir probabilidades a etiquetas (clase con mayor probabilidad)
#y_pred_classes = np.argmax(y_pred, axis=1)

val_batches = list(val_ds)
x_val = tf.concat([x for x, y in val_batches], axis=0)
y_true = tf.concat([y for x, y in val_batches], axis=0).numpy()

y_pred = model.predict(x_val)
y_pred_classes = np.argmax(y_pred, axis=1)

# Extraer etiquetas reales del dataset de prueba
y_true = tf.concat([y for x, y in val_ds], axis=0).numpy()

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
cm = confusion_matrix(y_true, y_pred_classes)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])
disp.plot(cmap="Blues")
plt.title("Matriz de Confusión")
plt.show()

"""# Despliegue del modelo II"""

!pwd

!ls

"""Vamos a aplicar el modelo para una imagen que corresponde a una radiografía de largeCell Carcinoma.

Las etiquetas de las clases son las siguientes:

'sin cancer' = 0,

'cancer' = 1,
"""

# Leer el archivo PNG
ruta_imagen = 'imagenprueba.jpeg'
imagen = Image.open(ruta_imagen)

# Mostrar la imagen
plt.imshow(imagen)
plt.axis('off')  # Opcional: Oculta los ejes
plt.title("Imagen PNG")
plt.show()

imagen = imagen.resize((128, 128))  # Resize a 32x32
# Convertir a array y normalizar
imagen_array = np.array(imagen) / 255.0

# Redimensionar para que tenga forma (1, 32, 32, 1)
ima0 = imagen_array.reshape(1, 128, 128, 1)

plt.imshow(imagen)
plt.title("Imagen Redimensionada (128x128)")
plt.axis('off')
plt.show()

model.input_shape

# Predecir con el modelo
prediccion = tf.argmax(model.predict(ima0), axis=1).numpy()
print(prediccion)